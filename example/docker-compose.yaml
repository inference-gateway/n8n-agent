---
services:
  inference-gateway:
    image: ghcr.io/inference-gateway/inference-gateway:latest
    container_name: inference-gateway
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      CLOUDFLARE_API_KEY: ${CLOUDFLARE_API_KEY}
      COHERE_API_KEY: ${COHERE_API_KEY}
      MISTRAL_API_KEY: ${MISTRAL_API_KEY}
      LOG_LEVEL: info
      ENVIRONMENT: production
      SERVER_READ_TIMEOUT: 530s
      SERVER_WRITE_TIMEOUT: 530s
      CLIENT_TIMEOUT: 530s
      CLIENT_IDLE_CONN_TIMEOUT: 130s
      CLIENT_RESPONSE_HEADER_TIMEOUT: 120s
    networks:
      - a2a-network

  agent:
    build:
      context: ..
    container_name: agent
    ports:
      - "8080:8080"
    environment:
      A2A_PORT: 8080
      A2A_DEBUG: true
      A2A_AGENT_CLIENT_PROVIDER: ${A2A_AGENT_CLIENT_PROVIDER}
      A2A_AGENT_CLIENT_MODEL: ${A2A_AGENT_CLIENT_MODEL}
      A2A_AGENT_CLIENT_BASE_URL: http://inference-gateway:8080/v1
      A2A_AGENT_STREAMING_ENABLED: true
      A2A_AGENT_CLIENT_TOOLS_CREATE_ARTIFACT: true
      A2A_STREAMING_STATUS_UPDATE_INTERVAL: 1s
      A2A_QUEUE_CLEANUP_INTERVAL: 500s
      A2A_ARTIFACTS_ENABLE: true
      A2A_ARTIFACTS_SERVER_HOST: agent
      A2A_ARTIFACTS_SERVER_PORT: 8081
      A2A_ARTIFACTS_STORAGE_PROVIDER: filesystem
      A2A_ARTIFACTS_STORAGE_BASE_PATH: /tmp/workflows
      A2A_AGENT_CLIENT_MAX_CHAT_COMPLETION_ITERATIONS: 30
    networks:
      - a2a-network

  cli:
    image: ghcr.io/inference-gateway/cli:latest
    container_name: cli
    pull_policy: always
    volumes:
      - ./downloads:/tmp/downloads
    environment:
      INFER_LOGGING_DEBUG: true
      INFER_GATEWAY_URL: http://inference-gateway:8080
      INFER_A2A_ENABLED: true
      INFER_TOOLS_ENABLED: false
      INFER_AGENT_MODEL: ${INFER_AGENT_MODEL}
      INFER_A2A_AGENTS: |
        http://agent:8080
      INFER_DOWNLOAD_DIR: /tmp/downloads
    command:
      - chat
    networks:
      - a2a-network
    profiles:
      - manual

  a2a-debugger:
    image: ghcr.io/inference-gateway/a2a-debugger:latest
    container_name: a2a-debugger
    pull_policy: always
    entrypoint:
      - /a2a
      - --server-url
      - http://agent:8080
      - --timeout
      - 500s
    networks:
      - a2a-network
    profiles:
      - manual

networks:
  a2a-network:
    driver: bridge
